{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter Gender Classification\n",
    "### Final Project\n",
    "\n",
    "#### University of California, Santa Barbara\n",
    "#### PSTAT 135: Big Data Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://www.kaggle.com/crowdflower/twitter-user-gender-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains about 20,000 rows, each with a user name, a random tweet, account profile and image, location, and link and sidebar color. All tweets were posted on October 26, 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"comm\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "tweets = spark.read.csv('gender_data.csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24230"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_unit_id',\n",
       " '_golden',\n",
       " '_unit_state',\n",
       " '_trusted_judgments',\n",
       " '_last_judgment_at',\n",
       " 'gender',\n",
       " 'gender:confidence',\n",
       " 'profile_yn',\n",
       " 'profile_yn:confidence',\n",
       " 'created',\n",
       " 'description',\n",
       " 'fav_number',\n",
       " 'gender_gold',\n",
       " 'link_color',\n",
       " 'name',\n",
       " 'profile_yn_gold',\n",
       " 'profileimage',\n",
       " 'retweet_count',\n",
       " 'sidebar_color',\n",
       " 'text',\n",
       " 'tweet_coord',\n",
       " 'tweet_count',\n",
       " 'tweet_created',\n",
       " 'tweet_id',\n",
       " 'tweet_location',\n",
       " 'user_timezone']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We removed columns `_golden`, `_unit_state`, `_last_judgment_at`, `gender:confidence`, `profile_yn`, `profile_yn:confidence`, `link_color`, `profile_yn_gold`, `profileimage`, and `sidebar_color` because they were not relevant in our model/purpose.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gender',\n",
       " 'created',\n",
       " 'description',\n",
       " 'fav_number',\n",
       " 'name',\n",
       " 'retweet_count',\n",
       " 'text',\n",
       " 'tweet_coord',\n",
       " 'tweet_count',\n",
       " 'tweet_created',\n",
       " 'tweet_id',\n",
       " 'tweet_location',\n",
       " 'user_timezone']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_drop = ['_unit_id','_golden','_unit_state','_trusted_judgments','_last_judgment_at',\n",
    "                   'gender:confidence','profile_yn','profile_yn:confidence','gender_gold',\n",
    "                   'profile_yn_gold','link_color','profileimage','sidebar_color']\n",
    "tweets = tweets.drop(*columns_to_drop)\n",
    "tweets.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In the `gender` column, we found that there were other labels besides `male`, `female`, and `brand`. Therefore, we are only going to keep rows where they have 1 of these 3 labels.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.filter((tweets.gender == 'male') | (tweets.gender == 'female') | (tweets.gender == 'brand'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18836"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From above, we see that after filtering gender, we have 18,836 rows. Next, we will check to see that each row has non-empty or non-null values in column `text`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17748"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of non-null values in \"text\"\n",
    "tweets.filter(tweets.text.isNotNull()).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we have 17,748 non-null values, so there is a presence of null values in this column. Thus, we will remove rows with null values, since actual text is important in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.filter(tweets.text.isNotNull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For columns `fav_number`, `retweet_count`, and `tweet_count`, we will check to see if there are null values.** \n",
    "\n",
    "- If more than 10% of the values are null, we will not include that column later on in our model. \n",
    "\n",
    "- If less than 10% of the values are null, we will replace null values with the median of that specific column. We chose median because there is a possibility the mean could be something like 77.5, and you cannot retweet something 77.5 times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fav_number` : Since there are no null values, there is no need to do any replacing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of null values in \"fav_number\"\n",
    "tweets.filter(tweets.fav_number.isNull()).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`retweet_count` : Since there are no null values, there is no need to do any replacing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of null values in \"retweet_count\"\n",
    "tweets.filter(tweets.retweet_count.isNull()).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tweet_count` : There appears to be 1,259 null values. Since null values make up less than 10% of this column, we will replace these null values with the median of this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1259"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of null values in \"tweet_count\"\n",
    "tweets.filter(tweets.tweet_count.isNull()).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We applied **Imputer** because it imputes missing values using mean (the default) or median in columns where missing values are located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median of \"tweet_count\"\n",
    "from pyspark.ml.feature import Imputer\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "tweets = tweets.withColumn(\"tweet_count\",tweets[\"tweet_count\"].cast(IntegerType()))\n",
    "imputer = Imputer(inputCols=[\"tweet_count\"], outputCols=[\"tweet_count_new\"]).setStrategy(\"median\")\n",
    "tweets = imputer.fit(tweets).transform(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will check to see if there are any null values left in the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.filter(tweets.tweet_count_new.isNull()).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We are interested in getting the number of years the twitter user has had there account, up to the date of the posted tweet we have in our data. We will create a row with this count of years and call it `account_years`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|       created|\n",
      "+--------------+\n",
      "|  12/5/13 1:48|\n",
      "| 10/1/12 13:51|\n",
      "|11/28/14 11:30|\n",
      "+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets.select('created').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| _1|\n",
      "+---+\n",
      "|  2|\n",
      "|  3|\n",
      "|  1|\n",
      "+---+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use rdd, extract only the \"year\" part of the date, subtract from \"15\" (representing 2015)\n",
    "rdd = tweets.rdd\n",
    "years = rdd.map(lambda row: row['created'].split(' ')) \\\n",
    "                .map(lambda x: x[0]) \\\n",
    "                .map(lambda x: x.split('/')) \\\n",
    "                .map(lambda x: x[2]) \\\n",
    "                .map(lambda x: (15-int(x))) \\\n",
    "                .map(lambda x: (x, )).toDF()\n",
    "years.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert back to dataframe, add calculated years to \"tweets\" as \"account_years\"\n",
    "tweets = tweets.join(years).withColumnRenamed('_1', 'account_years')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Gender: top 10 most used words, average number of favorites (`fav_number`), average number of retweets (`retween_count`), average number of tweets (`tweet_count`), average number of account years\n",
    "\n",
    "\n",
    "# CHECK ACCOUNT YEARS AND TOP 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Female**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 most used words\n",
    "#female = tweets.filter(tweets.gender == \"female\")\n",
    "#words = female.rdd.flatMap(lambda row: row['text'].split(' '))\n",
    "#wordcounts = words.map(lambda x: (x, 1)) \\\n",
    "                  #.reduceByKey(lambda x,y:x+y) \\\n",
    "                  #.map(lambda x:(x[1],x[0])) \\\n",
    "                  #.sortByKey(False)\n",
    "#wordcounts.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|  avg(fav_number)|\n",
      "+-----------------+\n",
      "|6039.206956248033|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fav_number average\n",
    "tweets.filter(tweets.gender == \"female\").agg({'fav_number':'avg'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "| avg(retweet_count)|\n",
      "+-------------------+\n",
      "|0.04737173434057287|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# retweet_count average\n",
    "tweets.filter(tweets.gender == \"female\").agg({'retweet_count':'avg'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "| avg(tweet_count)|\n",
      "+-----------------+\n",
      "|26868.96356206368|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tweet_count average\n",
    "tweets.filter(tweets.gender == \"female\").agg({'tweet_count':'avg'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|avg(account_years)|\n",
      "+------------------+\n",
      "|2.8274735181428894|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# account_years average\n",
    "tweets.filter(tweets.gender == \"female\").agg({'account_years':'avg'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Male**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 most used words\n",
    "#female = tweets.filter(tweets.gender == \"female\")\n",
    "#words = female.rdd.flatMap(lambda row: row['text'].split(' '))\n",
    "#wordcounts = words.map(lambda x: (x, 1)) \\\n",
    "                  #.reduceByKey(lambda x,y:x+y) \\\n",
    "                  #.map(lambda x:(x[1],x[0])) \\\n",
    "                  #.sortByKey(False)\n",
    "#wordcounts.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|  avg(fav_number)|\n",
      "+-----------------+\n",
      "|4929.307825484764|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fav_number average\n",
    "tweets.filter(tweets.gender == \"male\").agg({'fav_number':'avg'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "| avg(retweet_count)|\n",
      "+-------------------+\n",
      "|0.09279778393351801|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# retweet_count average\n",
    "tweets.filter(tweets.gender == \"male\").agg({'retweet_count':'avg'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "| avg(tweet_count)|\n",
      "+-----------------+\n",
      "|30534.52625698324|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tweet_count average\n",
    "tweets.filter(tweets.gender == \"male\").agg({'tweet_count':'avg'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|avg(account_years)|\n",
      "+------------------+\n",
      "|2.8274735181428894|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# account_years average\n",
    "tweets.filter(tweets.gender == \"male\").agg({'account_years':'avg'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural Language Processing (NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We derived features based on casing, punctuation, and emojis on the tweets in the `text` column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Casing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {False: 252068, True: 12995})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counts of Lowercase (True), Uppercase (False)\n",
    "\n",
    "words = rdd.flatMap(lambda row: row['text'].split(' '))\n",
    "wordcounts = words.map(lambda x: (x, 0)) \\\n",
    "                    .map(lambda x: x[0].isupper())\n",
    "wordcounts.countByValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04902608059216111"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "12995/(12995+252068)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 12,995 upper-case words in the `text` column. As you can see above, upper-case words make up less than 5% of the total words, so we do not think it is a heavily-weighted factor in deciding gender."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Punctuation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[': 96,\n",
       " '(': 18409,\n",
       " '=': 17774,\n",
       " \"'\": 32906,\n",
       " '#': 5809,\n",
       " ':': 11900,\n",
       " '/': 21656,\n",
       " '.': 21515,\n",
       " ')': 18566,\n",
       " ',': 22674,\n",
       " '\\\\': 430,\n",
       " '\"': 13310,\n",
       " '@': 7858,\n",
       " '-': 2266,\n",
       " '?': 1707,\n",
       " '!': 3546,\n",
       " '+': 129,\n",
       " '_': 7190,\n",
       " '%': 106,\n",
       " '&': 679,\n",
       " ';': 811,\n",
       " ']': 95,\n",
       " '|': 132,\n",
       " '$': 205,\n",
       " '~': 52,\n",
       " '*': 291,\n",
       " '^': 26,\n",
       " '{': 11,\n",
       " '}': 8,\n",
       " '`': 5}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count punctuation (!, ?, .)\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "\n",
    "counts = Counter(str(tweets.select('text').take(17748)))\n",
    "punctuation_counts = {k:v for k, v in counts.items() if k in punctuation}\n",
    "punctuation_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Emojis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'emoji'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-00b8050e75a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Count emojis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0memoji\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0memojis_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memoji\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNICODE_EMOJI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'emoji'"
     ]
    }
   ],
   "source": [
    "# Count emojis\n",
    "import emoji\n",
    "\n",
    "emojis_list = tweets.rdd.map(lambda x: ''.join(x.split()), emoji.UNICODE_EMOJI.keys()).collect()\n",
    "\n",
    "counts = Counter(str(tweets.select('text').take(17748)))\n",
    "emoji_counts = {k:v for k, v in counts.items() if k in emojis_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "[w for w in tweets.select('text').take(1) if any(c for c in w if unicodedata.category(c) == 'So')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we will process the tweets. We can monitor our changes by looking at row 1 of `text`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Casing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.select(\"text\").show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase words\n",
    "from pyspark.sql.functions import lower, col\n",
    "tweets = tweets.withColumn(\"text\",lower(col('text')))\n",
    "tweets.select(\"text\").show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tokenize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "tweets = tokenizer.transform(tweets)\n",
    "tweets.select(\"words\").show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stop Word Removal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Word Removal\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "tweets = remover.transform(tweets)\n",
    "tweets.select(\"filtered\").show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lemmatization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, StringIndexer, SQLTransformer,IndexToString\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "import sparknlp\n",
    "\n",
    "stemmer = Stemmer() \\\n",
    "    .setInputCols([\"cleanTokens\"]) \\\n",
    "    .setOutputCol(\"stem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
