{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter Gender Classification\n",
    "### Final Project\n",
    "\n",
    "#### University of California, Santa Barbara\n",
    "#### PSTAT 135: Big Data Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://www.kaggle.com/crowdflower/twitter-user-gender-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains about 20,000 rows, each with a user name, a random tweet, account profile and image, location, and link and sidebar color. All tweets were posted on October 26, 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"comm\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "tweets = spark.read.csv('gender_data.csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24230"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_unit_id',\n",
       " '_golden',\n",
       " '_unit_state',\n",
       " '_trusted_judgments',\n",
       " '_last_judgment_at',\n",
       " 'gender',\n",
       " 'gender:confidence',\n",
       " 'profile_yn',\n",
       " 'profile_yn:confidence',\n",
       " 'created',\n",
       " 'description',\n",
       " 'fav_number',\n",
       " 'gender_gold',\n",
       " 'link_color',\n",
       " 'name',\n",
       " 'profile_yn_gold',\n",
       " 'profileimage',\n",
       " 'retweet_count',\n",
       " 'sidebar_color',\n",
       " 'text',\n",
       " 'tweet_coord',\n",
       " 'tweet_count',\n",
       " 'tweet_created',\n",
       " 'tweet_id',\n",
       " 'tweet_location',\n",
       " 'user_timezone']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We removed columns `_golden`, `_unit_state`, `_last_judgment_at`, `gender:confidence`, `profile_yn`, `profile_yn:confidence`, `link_color`, `profile_yn_gold`, `profileimage`, and `sidebar_color` because they were not relevant in our model/purpose.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gender',\n",
       " 'created',\n",
       " 'description',\n",
       " 'fav_number',\n",
       " 'name',\n",
       " 'retweet_count',\n",
       " 'text',\n",
       " 'tweet_coord',\n",
       " 'tweet_count',\n",
       " 'tweet_created',\n",
       " 'tweet_id',\n",
       " 'tweet_location',\n",
       " 'user_timezone']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_drop = ['_unit_id','_golden','_unit_state','_trusted_judgments','_last_judgment_at',\n",
    "                   'gender:confidence','profile_yn','profile_yn:confidence','gender_gold',\n",
    "                   'profile_yn_gold','link_color','profileimage','sidebar_color']\n",
    "tweets = tweets.drop(*columns_to_drop)\n",
    "tweets.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In the `gender` column, we found that there were other labels besides `male`, `female`, and `brand`. Therefore, we are only going to keep rows where they have 1 of these 3 labels.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.filter((tweets.gender == 'male') | (tweets.gender == 'female') | (tweets.gender == 'brand'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18836"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From above, we see that after filtering gender, we have 18,836 rows. Next, we will check to see that each row has non-empty or non-null values in column `text`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17748"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of non-null values in \"text\"\n",
    "tweets.filter(tweets.text.isNotNull()).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we have 17,748 non-null values, so there is a presence of null values in this column. Thus, we will remove rows with null values, since actual text is important in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.filter(tweets.text.isNotNull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For columns `fav_number`, `retweet_count`, and `tweet_count`, we will check to see if there are null values.** \n",
    "\n",
    "- If more than 10% of the values are null, we will not include that column later on in our model. \n",
    "\n",
    "- If less than 10% of the values are null, we will replace null values with the median of that specific column. We chose median because there is a possibility the mean could be something like 77.5, and you cannot retweet something 77.5 times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fav_number` : Since there are no null values, there is no need to do any replacing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of null values in \"fav_number\"\n",
    "tweets.filter(tweets.fav_number.isNull()).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`retweet_count` : Since there are no null values, there is no need to do any replacing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of null values in \"retweet_count\"\n",
    "tweets.filter(tweets.retweet_count.isNull()).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tweet_count` : There appears to be 1,259 null values. Since null values make up less than 10% of this column, we will replace these null values with the median of this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1259"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of null values in \"tweet_count\"\n",
    "tweets.filter(tweets.tweet_count.isNull()).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We applied **Imputer** because it imputes missing values using mean (the default) or median in columns where missing values are located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median of \"tweet_count\"\n",
    "from pyspark.ml.feature import Imputer\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "tweets = tweets.withColumn(\"tweet_count\",tweets[\"tweet_count\"].cast(IntegerType()))\n",
    "imputer = Imputer(inputCols=[\"tweet_count\"], outputCols=[\"tweet_count_new\"]).setStrategy(\"median\")\n",
    "tweets = imputer.fit(tweets).transform(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will check to see if there are any null values left in the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.filter(tweets.tweet_count_new.isNull()).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We are interested in getting the number of years the twitter user has had there account, up to the date of the posted tweet we have in our data. We will create a row with this count of years and call it `account_years`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|       created|\n",
      "+--------------+\n",
      "|  12/5/13 1:48|\n",
      "| 10/1/12 13:51|\n",
      "|11/28/14 11:30|\n",
      "+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets.select('created').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| _1|\n",
      "+---+\n",
      "|  2|\n",
      "|  3|\n",
      "|  1|\n",
      "+---+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use rdd, extract only the \"year\" part of the date, subtract from \"15\" (representing 2015)\n",
    "rdd = tweets.rdd\n",
    "years = rdd.map(lambda row: row['created'].split(' ')) \\\n",
    "                .map(lambda x: x[0]) \\\n",
    "                .map(lambda x: x.split('/')) \\\n",
    "                .map(lambda x: x[2]) \\\n",
    "                .map(lambda x: (15-int(x))) \\\n",
    "                .map(lambda x: (x, )).toDF()\n",
    "years.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert back to dataframe, add calculated years to \"tweets\" as \"account_years\"\n",
    "tweets = tweets.join(years).withColumnRenamed('_1', 'account_years')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the counts and frequencies, average number of favorites (`fav_number`), average number of retweets (`retween_count`), average number of tweets (`tweet_count`), and average number of account years for each `gender` output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+\n",
      "|gender|    count|\n",
      "+------+---------+\n",
      "|female|112770792|\n",
      "|  male|102512448|\n",
      "| brand| 99708264|\n",
      "+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# counts\n",
    "tweets.groupBy('gender').count().orderBy('count',ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------+-----------------+-------------------+\n",
      "|avg(tweet_count)|avg(account_years)|  avg(fav_number)| avg(retweet_count)|\n",
      "+----------------+------------------+-----------------+-------------------+\n",
      "|63219.3443287037|2.8274735181428894|2086.142043431826|0.11765752936988252|\n",
      "+----------------+------------------+-----------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# brand averages\n",
    "tweets.filter(tweets.gender == \"brand\") \\\n",
    "            .agg({'fav_number':'avg','retweet_count':'avg','tweet_count':'avg', 'account_years':'avg'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------+-----------------+-------------------+\n",
      "| avg(tweet_count)|avg(account_years)|  avg(fav_number)| avg(retweet_count)|\n",
      "+-----------------+------------------+-----------------+-------------------+\n",
      "|26868.96356206368|2.8274735181428894|6039.206956248033|0.04737173434057287|\n",
      "+-----------------+------------------+-----------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# female averages\n",
    "tweets.filter(tweets.gender == \"female\") \\\n",
    "            .agg({'fav_number':'avg','retweet_count':'avg','tweet_count':'avg', 'account_years':'avg'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------+-----------------+-------------------+\n",
      "| avg(tweet_count)|avg(account_years)|  avg(fav_number)| avg(retweet_count)|\n",
      "+-----------------+------------------+-----------------+-------------------+\n",
      "|30534.52625698324|2.8274735181428894|4929.307825484764|0.09279778393351801|\n",
      "+-----------------+------------------+-----------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# male averages\n",
    "tweets.filter(tweets.gender == \"male\") \\\n",
    "            .agg({'fav_number':'avg','retweet_count':'avg','tweet_count':'avg', 'account_years':'avg'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural Language Processing (NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We derived features based on casing, punctuation, and emojis on the tweets in the `text` column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Casing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {False: 252068, True: 12995})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counts of Lowercase (True), Uppercase (False)\n",
    "\n",
    "words = rdd.flatMap(lambda row: row['text'].split(' '))\n",
    "wordcounts = words.map(lambda x: (x, 0)) \\\n",
    "                    .map(lambda x: x[0].isupper())\n",
    "wordcounts.countByValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04902608059216111"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "12995/(12995+252068)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 12,995 upper-case words in the `text` column. As you can see above, upper-case words make up less than 5% of the total words, so we do not think it is a heavily-weighted factor in deciding gender."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Punctuation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[': 96,\n",
       " '(': 18409,\n",
       " '=': 17774,\n",
       " \"'\": 32906,\n",
       " '#': 5809,\n",
       " ':': 11900,\n",
       " '/': 21656,\n",
       " '.': 21515,\n",
       " ')': 18566,\n",
       " ',': 22674,\n",
       " '\\\\': 430,\n",
       " '\"': 13310,\n",
       " '@': 7858,\n",
       " '-': 2266,\n",
       " '?': 1707,\n",
       " '!': 3546,\n",
       " '+': 129,\n",
       " '_': 7190,\n",
       " '%': 106,\n",
       " '&': 679,\n",
       " ';': 811,\n",
       " ']': 95,\n",
       " '|': 132,\n",
       " '$': 205,\n",
       " '~': 52,\n",
       " '*': 291,\n",
       " '^': 26,\n",
       " '{': 11,\n",
       " '}': 8,\n",
       " '`': 5}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count punctuation (!, ?, .)\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "\n",
    "counts = Counter(str(tweets.select('text').take(17748)))\n",
    "punctuation_counts = {k:v for k, v in counts.items() if k in punctuation}\n",
    "punctuation_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Emojis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count emojis\n",
    "import re\n",
    "\n",
    "tweets.createOrReplaceTempView(\"table1\")\n",
    "df2 = spark.sql(\"SELECT COUNT(text) FROM table1 WHERE text LIKE UNICODE(N'FFFD') \")\n",
    "df2.show(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "[w for w in tweets.select('text').take(1) if any(c for c in w if unicodedata.category(c) == 'So')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we will process the tweets. We can monitor our changes by looking at row 1 of `text`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Casing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------+\n",
      "|text                                                                                                         |\n",
      "+-------------------------------------------------------------------------------------------------------------+\n",
      "|Robbie E Responds To Critics After Win Against Eddie Edwards In The #WorldTitleSeries https://t.co/NSybBmVjKZ|\n",
      "+-------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets.select(\"text\").show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------+\n",
      "|text                                                                                                         |\n",
      "+-------------------------------------------------------------------------------------------------------------+\n",
      "|robbie e responds to critics after win against eddie edwards in the #worldtitleseries https://t.co/nsybbmvjkz|\n",
      "+-------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lowercase words\n",
    "from pyspark.sql.functions import lower, col\n",
    "tweets = tweets.withColumn(\"text\",lower(col('text')))\n",
    "tweets.select(\"text\").show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tokenize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------------+\n",
      "|words                                                                                                                       |\n",
      "+----------------------------------------------------------------------------------------------------------------------------+\n",
      "|[robbie, e, responds, to, critics, after, win, against, eddie, edwards, in, the, #worldtitleseries, https://t.co/nsybbmvjkz]|\n",
      "+----------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "tweets = tokenizer.transform(tweets)\n",
    "tweets.select(\"words\").show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stop Word Removal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------+\n",
      "|filtered                                                                                       |\n",
      "+-----------------------------------------------------------------------------------------------+\n",
      "|[robbie, e, responds, critics, win, eddie, edwards, #worldtitleseries, https://t.co/nsybbmvjkz]|\n",
      "+-----------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stop Word Removal\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "tweets = remover.transform(tweets)\n",
    "tweets.select(\"filtered\").show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stemming**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "\n",
    "stemmer = SnowballStemmer(language='english')\n",
    "stemmer_udf = udf(lambda tokens: [stemmer.stem(token) for token in tokens], ArrayType(StringType()))\n",
    "stem_tweets = tweets.withColumn(\"stemmed\", stemmer_udf(\"filtered\")).select(\"stemmed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stemmed']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_tweets.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we will apply Vector Assembler to prep the data for various ML models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [[Counts for each word], [Bigrams], [Punctuation counts, ** Emoji Counts **], tweets counts, favorited tweets, retweet counts, account years]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### HashingTF for stemmed tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.feature import HashingTF\n",
    "tf = HashingTF(numFeatures=10000)\n",
    "stem_features = stem_tweets.rdd.map(lambda tweet: tf.transform(tweet[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SparseVector(10000, {162: 1.0, 1521: 1.0, 1785: 1.0, 4032: 1.0, 5505: 1.0, 5993: 1.0, 6493: 1.0, 7437: 1.0, 9022: 1.0}),\n",
       " SparseVector(10000, {213: 1.0, 1065: 1.0, 1074: 1.0, 1136: 1.0, 2547: 1.0, 4623: 1.0, 6992: 1.0, 7449: 1.0, 8194: 1.0, 8854: 1.0, 9546: 1.0})]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_features.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Adding columns for counts of punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def punc_func(a):\n",
    "    if a in punctuation:\n",
    "        return true\n",
    "    return false\n",
    "\n",
    "punc = tweets.select(\"text\").rdd.map(lambda tweet: Counter(str(tweet)))\n",
    "punc_2 = punc.map(lambda x: list(x.keys())).map(lambda y: 1 if y[0] in punctuation else None)\n",
    "punc_2.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "         #.map(lambda y: y)).take(5)\n",
    "#punc_2 = punc.map(lambda x: list(x.keys())).map(lambda x: filter(punc_func, item) for item in x) \n",
    "         #lambda y: 1 if y in punctuation else None)\n",
    "#punc_2.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "#assembler = VectorAssembler(\n",
    "#   inputCols=[\"text\"],\n",
    "#    outputCol=\"features\")\n",
    "\n",
    "#output = assembler.transform(tweets)\n",
    "#output.select(\"features\", \"text\").show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
